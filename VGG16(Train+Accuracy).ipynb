{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('dataset')\n",
    "actions = np.array(['one', 'two','three', 'four', 'five', 'six', 'seven', 'eight', 'nine'])\n",
    "sequence_length = 100\n",
    "num_features = 126\n",
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "\n",
    "for action in actions:\n",
    "    action_path = os.path.join(DATA_PATH, action)\n",
    "    for sequence in np.array(os.listdir(action_path)).astype(int):\n",
    "        frame_paths = [\n",
    "            os.path.join(action_path, str(sequence), \"{}.npy\".format(frame_num))\n",
    "            for frame_num in range(sequence_length)\n",
    "        ]\n",
    "        window = [np.load(frame_path) for frame_path in frame_paths]\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('VGG16_Logs')\n",
    "callback = TensorBoard(log_dir=log_dir)\n",
    "ACCURACY_THRESHOLD = 0.95\n",
    "\n",
    "class MyCallback(tf.keras.callbacks.Callback): \n",
    "    def __init__(self, monitor_metric='accuracy', threshold=0.95):\n",
    "        super(MyCallback, self).__init__()\n",
    "        self.monitor_metric = monitor_metric\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        current_metric_value = logs.get(self.monitor_metric)\n",
    "        if current_metric_value is not None and current_metric_value > self.threshold:\n",
    "            print(f\"\\nReached {self.threshold * 100:.2f}% {self.monitor_metric}, stopping training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "my_callback = MyCallback(monitor_metric='accuracy', threshold=ACCURACY_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(64, 3, activation='relu', padding='same', input_shape=(sequence_length, num_features)))\n",
    "model.add(MaxPooling1D(2, strides=2))\n",
    "\n",
    "# Block 2\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2, strides=2))\n",
    "\n",
    "# Block 3\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(256, 3, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(256, 3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2, strides=2))\n",
    "\n",
    "# Block 4\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(512, 3, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(512, 3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2, strides=2))\n",
    "\n",
    "# Block 5\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(512, 3, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(512, 3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2, strides=2))\n",
    "\n",
    "# Flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully Connected Layers\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "158/158 [==============================] - 14s 26ms/step - loss: 2.6373 - accuracy: 0.1754 - val_loss: 2.3057 - val_accuracy: 0.1833\n",
      "Epoch 2/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 2.2755 - accuracy: 0.2921 - val_loss: 2.2725 - val_accuracy: 0.2759\n",
      "Epoch 3/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 2.1758 - accuracy: 0.3556 - val_loss: 2.0576 - val_accuracy: 0.4019\n",
      "Epoch 4/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 2.1748 - accuracy: 0.3643 - val_loss: 2.0784 - val_accuracy: 0.4111\n",
      "Epoch 5/100\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 2.1519 - accuracy: 0.3675 - val_loss: 2.2018 - val_accuracy: 0.4685\n",
      "Epoch 6/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 1.9917 - accuracy: 0.4095 - val_loss: 1.8647 - val_accuracy: 0.5315\n",
      "Epoch 7/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 2.0332 - accuracy: 0.4238 - val_loss: 1.2133 - val_accuracy: 0.6111\n",
      "Epoch 8/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 1.9169 - accuracy: 0.4651 - val_loss: 1.6649 - val_accuracy: 0.5630\n",
      "Epoch 9/100\n",
      "158/158 [==============================] - 3s 22ms/step - loss: 1.9017 - accuracy: 0.4587 - val_loss: 1.2453 - val_accuracy: 0.6259\n",
      "Epoch 10/100\n",
      "158/158 [==============================] - 3s 22ms/step - loss: 1.7444 - accuracy: 0.4825 - val_loss: 1.8290 - val_accuracy: 0.5667\n",
      "Epoch 11/100\n",
      "158/158 [==============================] - 3s 22ms/step - loss: 2.0560 - accuracy: 0.4532 - val_loss: 1.8878 - val_accuracy: 0.5259\n",
      "Epoch 12/100\n",
      "158/158 [==============================] - 4s 22ms/step - loss: 1.9547 - accuracy: 0.4595 - val_loss: 1.3914 - val_accuracy: 0.6389\n",
      "Epoch 13/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 1.7888 - accuracy: 0.5206 - val_loss: 1.4761 - val_accuracy: 0.6278\n",
      "Epoch 14/100\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 1.7973 - accuracy: 0.5230 - val_loss: 1.6413 - val_accuracy: 0.5852\n",
      "Epoch 15/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 1.6665 - accuracy: 0.5087 - val_loss: 1.4673 - val_accuracy: 0.5870\n",
      "Epoch 16/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 1.6205 - accuracy: 0.5437 - val_loss: 1.8136 - val_accuracy: 0.5778\n",
      "Epoch 17/100\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 1.6719 - accuracy: 0.5286 - val_loss: 1.4544 - val_accuracy: 0.6481\n",
      "Epoch 18/100\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 1.5379 - accuracy: 0.5603 - val_loss: 1.3796 - val_accuracy: 0.6722\n",
      "Epoch 19/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 1.5893 - accuracy: 0.5397 - val_loss: 1.3321 - val_accuracy: 0.6870\n",
      "Epoch 20/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 1.5834 - accuracy: 0.5548 - val_loss: 0.9104 - val_accuracy: 0.7130\n",
      "Epoch 21/100\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 1.3471 - accuracy: 0.6079 - val_loss: 1.3944 - val_accuracy: 0.6426\n",
      "Epoch 22/100\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 1.3798 - accuracy: 0.5937 - val_loss: 0.9802 - val_accuracy: 0.7370\n",
      "Epoch 23/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 1.3485 - accuracy: 0.5952 - val_loss: 1.2527 - val_accuracy: 0.6556\n",
      "Epoch 24/100\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 1.3844 - accuracy: 0.6016 - val_loss: 1.3906 - val_accuracy: 0.6333\n",
      "Epoch 25/100\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 1.4442 - accuracy: 0.6024 - val_loss: 1.7769 - val_accuracy: 0.6093\n",
      "Epoch 26/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 1.4758 - accuracy: 0.5873 - val_loss: 0.8720 - val_accuracy: 0.7407\n",
      "Epoch 27/100\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 1.3211 - accuracy: 0.6032 - val_loss: 1.0900 - val_accuracy: 0.6759\n",
      "Epoch 28/100\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 1.2113 - accuracy: 0.6476 - val_loss: 1.0384 - val_accuracy: 0.7111\n",
      "Epoch 29/100\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 1.3109 - accuracy: 0.6238 - val_loss: 1.3995 - val_accuracy: 0.6722\n",
      "Epoch 30/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 1.0918 - accuracy: 0.6563 - val_loss: 1.1070 - val_accuracy: 0.7352\n",
      "Epoch 31/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 1.1959 - accuracy: 0.6540 - val_loss: 0.7181 - val_accuracy: 0.7852\n",
      "Epoch 32/100\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 1.1481 - accuracy: 0.6603 - val_loss: 0.8407 - val_accuracy: 0.7556\n",
      "Epoch 33/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 1.1655 - accuracy: 0.6389 - val_loss: 1.3873 - val_accuracy: 0.7111\n",
      "Epoch 34/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 1.1062 - accuracy: 0.6825 - val_loss: 0.6251 - val_accuracy: 0.7907\n",
      "Epoch 35/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 1.1023 - accuracy: 0.6698 - val_loss: 0.8908 - val_accuracy: 0.7315\n",
      "Epoch 36/100\n",
      "158/158 [==============================] - 3s 22ms/step - loss: 1.2026 - accuracy: 0.6556 - val_loss: 0.6974 - val_accuracy: 0.7778\n",
      "Epoch 37/100\n",
      "158/158 [==============================] - 3s 22ms/step - loss: 1.2796 - accuracy: 0.6325 - val_loss: 1.1816 - val_accuracy: 0.7389\n",
      "Epoch 38/100\n",
      "158/158 [==============================] - 3s 22ms/step - loss: 1.0626 - accuracy: 0.6849 - val_loss: 0.8646 - val_accuracy: 0.7815\n",
      "Epoch 39/100\n",
      "158/158 [==============================] - 3s 22ms/step - loss: 1.0742 - accuracy: 0.6952 - val_loss: 1.3630 - val_accuracy: 0.6944\n",
      "Epoch 40/100\n",
      "158/158 [==============================] - 3s 22ms/step - loss: 1.0327 - accuracy: 0.6857 - val_loss: 0.6770 - val_accuracy: 0.8241\n",
      "Epoch 41/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 1.0366 - accuracy: 0.7040 - val_loss: 1.8853 - val_accuracy: 0.6815\n",
      "Epoch 42/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 0.9876 - accuracy: 0.6976 - val_loss: 0.9080 - val_accuracy: 0.7685\n",
      "Epoch 43/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 0.9053 - accuracy: 0.7119 - val_loss: 0.7458 - val_accuracy: 0.8056\n",
      "Epoch 44/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 0.9873 - accuracy: 0.7119 - val_loss: 0.7243 - val_accuracy: 0.8185\n",
      "Epoch 45/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 0.9275 - accuracy: 0.7254 - val_loss: 0.8682 - val_accuracy: 0.7833\n",
      "Epoch 46/100\n",
      "158/158 [==============================] - 3s 22ms/step - loss: 0.9706 - accuracy: 0.7190 - val_loss: 1.3058 - val_accuracy: 0.7204\n",
      "Epoch 47/100\n",
      "158/158 [==============================] - 3s 22ms/step - loss: 0.8933 - accuracy: 0.7270 - val_loss: 0.7923 - val_accuracy: 0.7926\n",
      "Epoch 48/100\n",
      "158/158 [==============================] - 3s 21ms/step - loss: 1.0460 - accuracy: 0.7032 - val_loss: 1.1564 - val_accuracy: 0.7259\n",
      "Epoch 49/100\n",
      "158/158 [==============================] - 4s 23ms/step - loss: 0.9022 - accuracy: 0.7103 - val_loss: 0.7189 - val_accuracy: 0.8204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f4b8e1cf0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=8, callbacks=[tb_callback, my_callback, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_2 (Batc  (None, 100, 126)         504       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 100, 64)           24256     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 50, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 50, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 25, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 25, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 25, 256)          1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 12, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 12, 256)          1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 12, 512)          2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 6, 512)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 6, 512)           2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 6, 512)            786944    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 6, 512)           2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 6, 512)            786944    \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 3, 512)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1536)              0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 1536)             6144      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              6295552   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 4096)             16384     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 36873     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,244,673\n",
      "Trainable params: 26,228,677\n",
      "Non-trainable params: 15,996\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('VGG16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('VGG16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 5ms/step\n",
      "Train Accuracy :-> \n",
      "87.6984126984127\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_train)\n",
    "ytrue = np.argmax(y_train, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "print(\"Train Accuracy :-> \")\n",
    "print(accuracy_score(ytrue, yhat)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 7ms/step\n",
      "Test Accuracy :-> \n",
      "79.07407407407408\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "print(\"Test Accuracy :-> \")\n",
    "print(accuracy_score(ytrue, yhat)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
