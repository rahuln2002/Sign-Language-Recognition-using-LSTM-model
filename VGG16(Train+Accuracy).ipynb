{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('dataset')\n",
    "actions = np.array(['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine'])\n",
    "sequence_length = 100\n",
    "num_features = 126\n",
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "\n",
    "for action in actions:\n",
    "    action_path = os.path.join(DATA_PATH, action)\n",
    "    for sequence in np.array(os.listdir(action_path)).astype(int):\n",
    "        frame_paths = [\n",
    "            os.path.join(action_path, str(sequence), \"{}.npy\".format(frame_num))\n",
    "            for frame_num in range(sequence_length)\n",
    "        ]\n",
    "        window = [np.load(frame_path) for frame_path in frame_paths]\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('VGG16_Logs')\n",
    "callback = TensorBoard(log_dir=log_dir)\n",
    "ACCURACY_THRESHOLD = 0.95\n",
    "\n",
    "class MyCallback(tf.keras.callbacks.Callback): \n",
    "    def __init__(self, monitor_metric='accuracy'):\n",
    "        super(MyCallback, self).__init__()\n",
    "        self.monitor_metric = monitor_metric\n",
    "        self.threshold = ACCURACY_THRESHOLD\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        current_metric_value = logs.get(self.monitor_metric)\n",
    "        if current_metric_value is not None and current_metric_value > self.threshold:\n",
    "            print(f\"\\nReached {self.threshold * 100:.2f}% {self.monitor_metric}, stopping training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "my_callback = MyCallback(monitor_metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(64, 3, activation='relu', padding='same', input_shape=(sequence_length, num_features)))\n",
    "model.add(MaxPooling1D(2, strides=2))\n",
    "\n",
    "# Block 2\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2, strides=2))\n",
    "\n",
    "# Block 3\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(256, 3, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(256, 3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2, strides=2))\n",
    "\n",
    "# Block 4\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(512, 3, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(512, 3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2, strides=2))\n",
    "\n",
    "# Block 5\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(512, 3, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(512, 3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2, strides=2))\n",
    "\n",
    "# Flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully Connected Layers\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 4/88 [>.............................] - ETA: 1s - loss: 2.9277 - accuracy: 0.0938  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0124s vs `on_train_batch_end` time: 0.0817s). Check your callbacks.\n",
      "88/88 [==============================] - 9s 31ms/step - loss: 2.4018 - accuracy: 0.2407 - val_loss: 2.4496 - val_accuracy: 0.1017\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.7049 - accuracy: 0.4493 - val_loss: 2.8303 - val_accuracy: 0.1050\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 1.6033 - accuracy: 0.4779 - val_loss: 2.6186 - val_accuracy: 0.2183\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.4403 - accuracy: 0.5371 - val_loss: 2.3800 - val_accuracy: 0.2900\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.2549 - accuracy: 0.5979 - val_loss: 1.9148 - val_accuracy: 0.4100\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.1603 - accuracy: 0.6271 - val_loss: 1.7599 - val_accuracy: 0.4917\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.1895 - accuracy: 0.6264 - val_loss: 1.0149 - val_accuracy: 0.6567\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 1.1380 - accuracy: 0.6479 - val_loss: 1.1384 - val_accuracy: 0.6483\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.0097 - accuracy: 0.6893 - val_loss: 0.9335 - val_accuracy: 0.7100\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.9064 - accuracy: 0.7136 - val_loss: 0.9417 - val_accuracy: 0.7367\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.9409 - accuracy: 0.6979 - val_loss: 0.9498 - val_accuracy: 0.7367\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 0.8611 - accuracy: 0.7329 - val_loss: 0.8361 - val_accuracy: 0.7683\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 0.8460 - accuracy: 0.7500 - val_loss: 0.8078 - val_accuracy: 0.7633\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.8542 - accuracy: 0.7471 - val_loss: 1.0650 - val_accuracy: 0.7617\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.8100 - accuracy: 0.7579 - val_loss: 0.9782 - val_accuracy: 0.7483\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.7747 - accuracy: 0.7679 - val_loss: 0.8301 - val_accuracy: 0.7733\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 0.8076 - accuracy: 0.7679 - val_loss: 0.6229 - val_accuracy: 0.8350\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.7231 - accuracy: 0.7864 - val_loss: 0.8010 - val_accuracy: 0.8033\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.6756 - accuracy: 0.8043 - val_loss: 0.8877 - val_accuracy: 0.8050\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.6263 - accuracy: 0.8086 - val_loss: 0.9371 - val_accuracy: 0.7867\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 0.6198 - accuracy: 0.8093 - val_loss: 0.5893 - val_accuracy: 0.8383\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.5317 - accuracy: 0.8457 - val_loss: 0.6576 - val_accuracy: 0.8200\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.6435 - accuracy: 0.8250 - val_loss: 0.9750 - val_accuracy: 0.7900\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.5141 - accuracy: 0.8393 - val_loss: 0.6978 - val_accuracy: 0.8433\n",
      "Epoch 25/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.4927 - accuracy: 0.8550 - val_loss: 0.6841 - val_accuracy: 0.8483\n",
      "Epoch 26/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.4783 - accuracy: 0.8571 - val_loss: 0.6525 - val_accuracy: 0.8667\n",
      "Epoch 27/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.5449 - accuracy: 0.8471 - val_loss: 1.0398 - val_accuracy: 0.7767\n",
      "Epoch 28/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.5293 - accuracy: 0.8600 - val_loss: 0.7803 - val_accuracy: 0.8450\n",
      "Epoch 29/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 0.4212 - accuracy: 0.8679 - val_loss: 0.4485 - val_accuracy: 0.8950\n",
      "Epoch 30/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.4781 - accuracy: 0.8650 - val_loss: 0.7355 - val_accuracy: 0.8650\n",
      "Epoch 31/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.4889 - accuracy: 0.8514 - val_loss: 0.5725 - val_accuracy: 0.8633\n",
      "Epoch 32/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.4943 - accuracy: 0.8614 - val_loss: 0.6876 - val_accuracy: 0.8467\n",
      "Epoch 33/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.4779 - accuracy: 0.8629 - val_loss: 0.6525 - val_accuracy: 0.8767\n",
      "Epoch 34/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.4937 - accuracy: 0.8571 - val_loss: 1.2080 - val_accuracy: 0.7617\n",
      "Epoch 35/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.4863 - accuracy: 0.8621 - val_loss: 0.6586 - val_accuracy: 0.8617\n",
      "Epoch 36/100\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.3433 - accuracy: 0.8903\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 0.3580 - accuracy: 0.8879 - val_loss: 0.4788 - val_accuracy: 0.9167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a7c7883550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=16, callbacks=[tb_callback, my_callback, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 100, 126)         504       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 100, 64)           24256     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 50, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 50, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 25, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 25, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 25, 256)          1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 12, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 12, 256)          1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 12, 512)          2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 6, 512)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 6, 512)           2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 6, 512)            786944    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 6, 512)           2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 6, 512)            786944    \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 3, 512)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1536)              0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 1536)             6144      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              6295552   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 4096)             16384     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                40970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,248,770\n",
      "Trainable params: 26,232,774\n",
      "Non-trainable params: 15,996\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('VGG16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('VGG16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 6ms/step\n",
      "Train Accuracy :-> \n",
      "88.18256475674653\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_train)\n",
    "ytrue = np.argmax(y_train, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "print(\"Train Accuracy :-> \")\n",
    "print(accuracy_score(ytrue, yhat)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 14ms/step\n",
      "Test Accuracy :-> \n",
      "83.33333333333333\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "print(\"Test Accuracy :-> \")\n",
    "print(accuracy_score(ytrue, yhat)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
