{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('dataset')\n",
    "actions = np.array(['one', 'two','three', 'four', 'five', 'six', 'seven', 'eight', 'nine'])\n",
    "sequence_length = 100\n",
    "num_features = 126\n",
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "\n",
    "for action in actions:\n",
    "    action_path = os.path.join(DATA_PATH, action)\n",
    "    for sequence in np.array(os.listdir(action_path)).astype(int):\n",
    "        frame_paths = [\n",
    "            os.path.join(action_path, str(sequence), \"{}.npy\".format(frame_num))\n",
    "            for frame_num in range(sequence_length)\n",
    "        ]\n",
    "        window = [np.load(frame_path) for frame_path in frame_paths]\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "callback = TensorBoard(log_dir=log_dir)\n",
    "ACCURACY_THRESHOLD = 0.95\n",
    "\n",
    "class MyCallback(tf.keras.callbacks.Callback): \n",
    "    def __init__(self, monitor_metric='accuracy', threshold=0.95):\n",
    "        super(MyCallback, self).__init__()\n",
    "        self.monitor_metric = monitor_metric\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        current_metric_value = logs.get(self.monitor_metric)\n",
    "        if current_metric_value is not None and current_metric_value > self.threshold:\n",
    "            print(f\"\\nReached {self.threshold * 100:.2f}% {self.monitor_metric}, stopping training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "my_callback = MyCallback(monitor_metric='accuracy', threshold=ACCURACY_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(16, return_sequences=True, input_shape=(sequence_length, num_features), activation='tanh', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(16, return_sequences=True))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(16, return_sequences=True))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(2048, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1536, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 6/40 [===>..........................] - ETA: 2s - loss: 0.3658 - accuracy: 0.8906WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0504s vs `on_train_batch_end` time: 0.0650s). Check your callbacks.\n",
      "40/40 [==============================] - 2s 52ms/step - loss: 0.4600 - accuracy: 0.8651 - val_loss: 0.8749 - val_accuracy: 0.7037\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.4480 - accuracy: 0.8635 - val_loss: 1.3976 - val_accuracy: 0.6204\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.5036 - accuracy: 0.8516 - val_loss: 0.9429 - val_accuracy: 0.7167\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.5115 - accuracy: 0.8349 - val_loss: 0.4813 - val_accuracy: 0.8611\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.4458 - accuracy: 0.8722 - val_loss: 1.3080 - val_accuracy: 0.6556\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.4595 - accuracy: 0.8714 - val_loss: 0.4456 - val_accuracy: 0.8704\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.5340 - accuracy: 0.8381 - val_loss: 0.9869 - val_accuracy: 0.7593\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6056 - accuracy: 0.8230 - val_loss: 0.7421 - val_accuracy: 0.7685\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.4904 - accuracy: 0.8548 - val_loss: 0.6043 - val_accuracy: 0.8278\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.4551 - accuracy: 0.8619 - val_loss: 0.4816 - val_accuracy: 0.8500\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.3760 - accuracy: 0.8857 - val_loss: 0.4085 - val_accuracy: 0.8519\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.4266 - accuracy: 0.8778 - val_loss: 0.6316 - val_accuracy: 0.8222\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.4534 - accuracy: 0.8810 - val_loss: 0.4077 - val_accuracy: 0.8778\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.3298 - accuracy: 0.9175 - val_loss: 0.8338 - val_accuracy: 0.7444\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.4689 - accuracy: 0.8643 - val_loss: 0.6082 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.3670 - accuracy: 0.9008 - val_loss: 0.5032 - val_accuracy: 0.8370\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.3614 - accuracy: 0.9071 - val_loss: 0.5275 - val_accuracy: 0.8500\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.4545 - accuracy: 0.8675 - val_loss: 0.7638 - val_accuracy: 0.7630\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.4223 - accuracy: 0.8802 - val_loss: 1.2845 - val_accuracy: 0.6722\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.3529 - accuracy: 0.9079 - val_loss: 0.5238 - val_accuracy: 0.8444\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.3413 - accuracy: 0.9040 - val_loss: 0.6628 - val_accuracy: 0.7926\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.3999 - accuracy: 0.8984 - val_loss: 0.4956 - val_accuracy: 0.8500\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.3144 - accuracy: 0.9222 - val_loss: 0.9234 - val_accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.3650 - accuracy: 0.9032 - val_loss: 0.9583 - val_accuracy: 0.7407\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.3799 - accuracy: 0.8905 - val_loss: 0.7051 - val_accuracy: 0.7907\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.4409 - accuracy: 0.8714 - val_loss: 0.3894 - val_accuracy: 0.9000\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.3769 - accuracy: 0.9063 - val_loss: 0.6338 - val_accuracy: 0.7926\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.3096 - accuracy: 0.9198 - val_loss: 0.4666 - val_accuracy: 0.8685\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.3180 - accuracy: 0.9167 - val_loss: 0.5630 - val_accuracy: 0.8222\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.3417 - accuracy: 0.9071 - val_loss: 0.8528 - val_accuracy: 0.7333\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.3533 - accuracy: 0.9056 - val_loss: 0.6103 - val_accuracy: 0.8204\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.3295 - accuracy: 0.9119 - val_loss: 0.8875 - val_accuracy: 0.7556\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.2878 - accuracy: 0.9341 - val_loss: 0.4349 - val_accuracy: 0.8963\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.3323 - accuracy: 0.9119 - val_loss: 0.6260 - val_accuracy: 0.8130\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.3574 - accuracy: 0.9095 - val_loss: 0.4015 - val_accuracy: 0.8852\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.3158 - accuracy: 0.9254 - val_loss: 0.4651 - val_accuracy: 0.8685\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.3389 - accuracy: 0.9087 - val_loss: 0.7184 - val_accuracy: 0.8167\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.2876 - accuracy: 0.9278 - val_loss: 0.4227 - val_accuracy: 0.9000\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.2972 - accuracy: 0.9214 - val_loss: 0.4794 - val_accuracy: 0.8648\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.2700 - accuracy: 0.9357 - val_loss: 0.8535 - val_accuracy: 0.7926\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2343 - accuracy: 0.9540\n",
      "Reached 95.00% accuracy, stopping training!\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.2343 - accuracy: 0.9540 - val_loss: 0.4077 - val_accuracy: 0.8926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19ade51c2b0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=32, callbacks=[tb_callback, my_callback, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_39 (Bat  (None, 100, 126)         504       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_34 (LSTM)              (None, 100, 16)           9152      \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 100, 16)          64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 100, 32)           6272      \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 100, 32)           0         \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 100, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_36 (LSTM)              (None, 100, 16)           3136      \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 100, 16)          64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_37 (LSTM)              (None, 100, 16)           2112      \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 2048)              3278848   \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1536)              3147264   \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1024)              1573888   \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 9)                 9225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,030,657\n",
      "Trainable params: 8,030,277\n",
      "Non-trainable params: 380\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 19ms/step\n",
      "Train Accuracy :-> \n",
      "96.19047619047619\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_train)\n",
    "ytrue = np.argmax(y_train, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "print(\"Train Accuracy :-> \")\n",
    "print(accuracy_score(ytrue, yhat)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 18ms/step\n",
      "Test Accuracy :-> \n",
      "90.0\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "print(\"Test Accuracy :-> \")\n",
    "print(accuracy_score(ytrue, yhat)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
