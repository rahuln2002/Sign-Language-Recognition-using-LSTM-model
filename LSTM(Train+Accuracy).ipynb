{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('dataset')\n",
    "actions = np.array(['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine'])\n",
    "sequence_length = 100\n",
    "num_features = 126\n",
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "\n",
    "for action in actions:\n",
    "    action_path = os.path.join(DATA_PATH, action)\n",
    "    for sequence in np.array(os.listdir(action_path)).astype(int):\n",
    "        frame_paths = [\n",
    "            os.path.join(action_path, str(sequence), \"{}.npy\".format(frame_num))\n",
    "            for frame_num in range(sequence_length)\n",
    "        ]\n",
    "        window = [np.load(frame_path) for frame_path in frame_paths]\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('LSTM_Logs_zero')\n",
    "callback = TensorBoard(log_dir=log_dir)\n",
    "ACCURACY_THRESHOLD = 0.95\n",
    "\n",
    "class MyCallback(tf.keras.callbacks.Callback): \n",
    "    def __init__(self, monitor_metric='accuracy', threshold=0.95):\n",
    "        super(MyCallback, self).__init__()\n",
    "        self.monitor_metric = monitor_metric\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        current_metric_value = logs.get(self.monitor_metric)\n",
    "        if current_metric_value is not None and current_metric_value > self.threshold:\n",
    "            print(f\"\\nReached {self.threshold * 100:.2f}% {self.monitor_metric}, stopping training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "my_callback = MyCallback(monitor_metric='accuracy', threshold=ACCURACY_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(16, return_sequences=True, input_shape=(sequence_length, num_features), activation='tanh', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(16, return_sequences=True))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(16, return_sequences=True))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(2048, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1536, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 6/44 [===>..........................] - ETA: 3s - loss: 4.6442 - accuracy: 0.0938WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0469s vs `on_train_batch_end` time: 0.3631s). Check your callbacks.\n",
      "44/44 [==============================] - 18s 84ms/step - loss: 3.7142 - accuracy: 0.2586 - val_loss: 3.6384 - val_accuracy: 0.1200\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 2s 45ms/step - loss: 2.7167 - accuracy: 0.3807 - val_loss: 3.1966 - val_accuracy: 0.1183\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 2.1136 - accuracy: 0.4521 - val_loss: 2.6980 - val_accuracy: 0.1867\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 1.7754 - accuracy: 0.4993 - val_loss: 2.5477 - val_accuracy: 0.2300\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 1.4981 - accuracy: 0.5736 - val_loss: 2.1224 - val_accuracy: 0.2450\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 1.3210 - accuracy: 0.5950 - val_loss: 2.1601 - val_accuracy: 0.3267\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 1.1627 - accuracy: 0.6407 - val_loss: 2.5204 - val_accuracy: 0.2117\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 2s 45ms/step - loss: 1.0673 - accuracy: 0.6750 - val_loss: 1.3277 - val_accuracy: 0.4900\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 1.0102 - accuracy: 0.6586 - val_loss: 1.4518 - val_accuracy: 0.4267\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 0.9239 - accuracy: 0.6843 - val_loss: 1.0248 - val_accuracy: 0.6033\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.8472 - accuracy: 0.7236 - val_loss: 1.9310 - val_accuracy: 0.4433\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 0.8636 - accuracy: 0.7150 - val_loss: 1.7568 - val_accuracy: 0.4700\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 0.8944 - accuracy: 0.7171 - val_loss: 1.2884 - val_accuracy: 0.5583\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 0.8680 - accuracy: 0.7136 - val_loss: 0.7476 - val_accuracy: 0.7200\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 0.8236 - accuracy: 0.7293 - val_loss: 1.0695 - val_accuracy: 0.6533\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 2s 45ms/step - loss: 0.7894 - accuracy: 0.7350 - val_loss: 0.6330 - val_accuracy: 0.7817\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.6935 - accuracy: 0.7614 - val_loss: 0.9808 - val_accuracy: 0.6550\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 0.7466 - accuracy: 0.7671 - val_loss: 0.7257 - val_accuracy: 0.7750\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.6538 - accuracy: 0.7986 - val_loss: 0.6626 - val_accuracy: 0.7767\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.6507 - accuracy: 0.7993 - val_loss: 0.9205 - val_accuracy: 0.6933\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.6178 - accuracy: 0.8071 - val_loss: 0.5813 - val_accuracy: 0.8150\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.5453 - accuracy: 0.8336 - val_loss: 0.6499 - val_accuracy: 0.7933\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.6165 - accuracy: 0.8264 - val_loss: 0.6677 - val_accuracy: 0.7883\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.6202 - accuracy: 0.8107 - val_loss: 0.7368 - val_accuracy: 0.7783\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.5395 - accuracy: 0.8436 - val_loss: 1.1554 - val_accuracy: 0.6683\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.5074 - accuracy: 0.8536 - val_loss: 0.6279 - val_accuracy: 0.7967\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.5395 - accuracy: 0.8464 - val_loss: 1.1427 - val_accuracy: 0.6783\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.5231 - accuracy: 0.8407 - val_loss: 0.4782 - val_accuracy: 0.8533\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.5050 - accuracy: 0.8579 - val_loss: 1.0667 - val_accuracy: 0.6950\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.5620 - accuracy: 0.8286 - val_loss: 0.8036 - val_accuracy: 0.7383\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.4975 - accuracy: 0.8643 - val_loss: 0.4197 - val_accuracy: 0.8733\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.4349 - accuracy: 0.8829 - val_loss: 0.5586 - val_accuracy: 0.8150\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.4441 - accuracy: 0.8793 - val_loss: 1.4297 - val_accuracy: 0.6417\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.4524 - accuracy: 0.8736 - val_loss: 0.9771 - val_accuracy: 0.7317\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.4696 - accuracy: 0.8750 - val_loss: 0.4107 - val_accuracy: 0.8850\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.4638 - accuracy: 0.8764 - val_loss: 0.6049 - val_accuracy: 0.8100\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.4694 - accuracy: 0.8636 - val_loss: 0.8973 - val_accuracy: 0.7417\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.4462 - accuracy: 0.8771 - val_loss: 0.6040 - val_accuracy: 0.8133\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.3896 - accuracy: 0.8907 - val_loss: 0.5723 - val_accuracy: 0.8600\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.4120 - accuracy: 0.8843 - val_loss: 0.6542 - val_accuracy: 0.7833\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.3974 - accuracy: 0.8986 - val_loss: 0.3836 - val_accuracy: 0.9000\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.3609 - accuracy: 0.9121 - val_loss: 0.4051 - val_accuracy: 0.8867\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.4356 - accuracy: 0.8929 - val_loss: 0.6846 - val_accuracy: 0.7883\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.3859 - accuracy: 0.9014 - val_loss: 0.8810 - val_accuracy: 0.7650\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.3644 - accuracy: 0.9093 - val_loss: 0.3252 - val_accuracy: 0.9150\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.3701 - accuracy: 0.9129 - val_loss: 0.4245 - val_accuracy: 0.8767\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.3875 - accuracy: 0.8957 - val_loss: 1.0438 - val_accuracy: 0.7517\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.3243 - accuracy: 0.9207 - val_loss: 0.5318 - val_accuracy: 0.8583\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.3789 - accuracy: 0.9079 - val_loss: 0.5919 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.3843 - accuracy: 0.9000 - val_loss: 0.5245 - val_accuracy: 0.8533\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.3258 - accuracy: 0.9143 - val_loss: 0.4909 - val_accuracy: 0.8517\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.3519 - accuracy: 0.9086 - val_loss: 0.5638 - val_accuracy: 0.8367\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.3557 - accuracy: 0.9029 - val_loss: 0.4521 - val_accuracy: 0.8800\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.4139 - accuracy: 0.8900 - val_loss: 0.3721 - val_accuracy: 0.9150\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.3687 - accuracy: 0.9057 - val_loss: 0.8630 - val_accuracy: 0.7750\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.3133 - accuracy: 0.9171 - val_loss: 0.3953 - val_accuracy: 0.9167\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.3130 - accuracy: 0.9286 - val_loss: 0.4656 - val_accuracy: 0.8733\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.3260 - accuracy: 0.9171 - val_loss: 0.7746 - val_accuracy: 0.7833\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.2953 - accuracy: 0.9300 - val_loss: 0.5951 - val_accuracy: 0.8483\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 0.3100 - accuracy: 0.9257 - val_loss: 0.8138 - val_accuracy: 0.7833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x222d4e2fbb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=32, callbacks=[tb_callback, my_callback, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 100, 126)         504       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100, 16)           9152      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 100, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100, 32)           6272      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 32)           0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 100, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100, 16)           3136      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 100, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 100, 16)           2112      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              3278848   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1536)              3147264   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              1573888   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,031,682\n",
      "Trainable params: 8,031,302\n",
      "Non-trainable params: 380\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 2s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 2s 17ms/step\n",
      "Train Accuracy :-> \n",
      "94.28571428571428\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_train)\n",
    "ytrue = np.argmax(y_train, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "print(\"Train Accuracy :-> \")\n",
    "print(accuracy_score(ytrue, yhat)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 13ms/step\n",
      "Test Accuracy :-> \n",
      "91.5\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "print(\"Test Accuracy :-> \")\n",
    "print(accuracy_score(ytrue, yhat)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
