{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Add, MaxPooling1D, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('dataset')\n",
    "actions = np.array(['one', 'two','three', 'four', 'five', 'six', 'seven', 'eight', 'nine'])\n",
    "sequence_length = 100\n",
    "num_features = 126\n",
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "\n",
    "for action in actions:\n",
    "    action_path = os.path.join(DATA_PATH, action)\n",
    "    for sequence in np.array(os.listdir(action_path)).astype(int):\n",
    "        frame_paths = [\n",
    "            os.path.join(action_path, str(sequence), \"{}.npy\".format(frame_num))\n",
    "            for frame_num in range(sequence_length)\n",
    "        ]\n",
    "        window = [np.load(frame_path) for frame_path in frame_paths]\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('ResNet_Logs')\n",
    "callback = TensorBoard(log_dir=log_dir)\n",
    "ACCURACY_THRESHOLD = 0.95\n",
    "\n",
    "class MyCallback(tf.keras.callbacks.Callback): \n",
    "    def __init__(self, monitor_metric='accuracy', threshold=0.95):\n",
    "        super(MyCallback, self).__init__()\n",
    "        self.monitor_metric = monitor_metric\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        current_metric_value = logs.get(self.monitor_metric)\n",
    "        if current_metric_value is not None and current_metric_value > self.threshold:\n",
    "            print(f\"\\nReached {self.threshold * 100:.2f}% {self.monitor_metric}, stopping training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "my_callback = MyCallback(monitor_metric='accuracy', threshold=ACCURACY_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Add, MaxPooling1D, GlobalAveragePooling1D, Dense\n",
    "\n",
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    # Shortcut path\n",
    "    shortcut = x\n",
    "    \n",
    "    # Main path\n",
    "    x = Conv1D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Resize the shortcut to match the shape of x\n",
    "    shortcut = Conv1D(filters, 1, strides=stride, padding='same')(shortcut)\n",
    "    \n",
    "    # Add shortcut to main path\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x  # Return the updated tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Initial Convolution\n",
    "model.add(Conv1D(64, kernel_size=7, padding='same', input_shape=(sequence_length, num_features)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Residual Blocks\n",
    "input_tensor = model.output  # Save the original output tensor\n",
    "\n",
    "x = residual_block(input_tensor, filters=64)\n",
    "x = residual_block(x, filters=64)\n",
    "x = MaxPooling1D(2)(x)\n",
    "\n",
    "x = residual_block(x, filters=128, stride=2)\n",
    "x = residual_block(x, filters=128)\n",
    "x = MaxPooling1D(2)(x)\n",
    "\n",
    "x = residual_block(x, filters=256, stride=2)\n",
    "x = residual_block(x, filters=256)\n",
    "x = MaxPooling1D(2)(x)\n",
    "\n",
    "x = residual_block(x, filters=512, stride=2)\n",
    "x = residual_block(x, filters=512)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "# Fully Connected Layers\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "output_tensor = Dense(actions.shape[0], activation='softmax')(x)\n",
    "\n",
    "# Create a Model with input and output\n",
    "model = Model(inputs=model.input, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "158/158 [==============================] - 14s 35ms/step - loss: 2.4139 - accuracy: 0.1730 - val_loss: 2.2447 - val_accuracy: 0.1037\n",
      "Epoch 2/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 2.1785 - accuracy: 0.2079 - val_loss: 2.2201 - val_accuracy: 0.1704\n",
      "Epoch 3/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 2.0690 - accuracy: 0.2413 - val_loss: 2.0084 - val_accuracy: 0.2907\n",
      "Epoch 4/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 1.9722 - accuracy: 0.2651 - val_loss: 1.9660 - val_accuracy: 0.2574\n",
      "Epoch 5/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 1.9431 - accuracy: 0.2706 - val_loss: 2.2679 - val_accuracy: 0.2630\n",
      "Epoch 6/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 1.8462 - accuracy: 0.3000 - val_loss: 1.8210 - val_accuracy: 0.2944\n",
      "Epoch 7/100\n",
      "158/158 [==============================] - 4s 28ms/step - loss: 1.7662 - accuracy: 0.3206 - val_loss: 1.6259 - val_accuracy: 0.3333\n",
      "Epoch 8/100\n",
      "158/158 [==============================] - 4s 28ms/step - loss: 1.7152 - accuracy: 0.3603 - val_loss: 1.5896 - val_accuracy: 0.3759\n",
      "Epoch 9/100\n",
      "158/158 [==============================] - 4s 28ms/step - loss: 1.6042 - accuracy: 0.3849 - val_loss: 1.6041 - val_accuracy: 0.3963\n",
      "Epoch 10/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 1.5597 - accuracy: 0.3873 - val_loss: 1.6369 - val_accuracy: 0.3870\n",
      "Epoch 11/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 1.4261 - accuracy: 0.4294 - val_loss: 1.5273 - val_accuracy: 0.4222\n",
      "Epoch 12/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 1.4203 - accuracy: 0.4365 - val_loss: 1.5437 - val_accuracy: 0.3870\n",
      "Epoch 13/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 1.3452 - accuracy: 0.4619 - val_loss: 1.5790 - val_accuracy: 0.3944\n",
      "Epoch 14/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 1.3039 - accuracy: 0.4873 - val_loss: 1.3614 - val_accuracy: 0.4296\n",
      "Epoch 15/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 1.2817 - accuracy: 0.4921 - val_loss: 1.3259 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 1.2861 - accuracy: 0.4881 - val_loss: 1.4784 - val_accuracy: 0.4111\n",
      "Epoch 17/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 1.2484 - accuracy: 0.5048 - val_loss: 1.1981 - val_accuracy: 0.4796\n",
      "Epoch 18/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 1.1650 - accuracy: 0.5444 - val_loss: 1.0569 - val_accuracy: 0.5519\n",
      "Epoch 19/100\n",
      "158/158 [==============================] - 4s 28ms/step - loss: 1.1472 - accuracy: 0.5635 - val_loss: 1.1673 - val_accuracy: 0.5241\n",
      "Epoch 20/100\n",
      "158/158 [==============================] - 4s 28ms/step - loss: 1.2262 - accuracy: 0.5214 - val_loss: 1.3621 - val_accuracy: 0.4981\n",
      "Epoch 21/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 1.0864 - accuracy: 0.5659 - val_loss: 1.3271 - val_accuracy: 0.5241\n",
      "Epoch 22/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 1.0407 - accuracy: 0.5786 - val_loss: 1.1636 - val_accuracy: 0.4926\n",
      "Epoch 23/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 0.9604 - accuracy: 0.6222 - val_loss: 1.5309 - val_accuracy: 0.4593\n",
      "Epoch 24/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 1.0717 - accuracy: 0.5802 - val_loss: 1.2589 - val_accuracy: 0.5241\n",
      "Epoch 25/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 1.0249 - accuracy: 0.5881 - val_loss: 1.1131 - val_accuracy: 0.5093\n",
      "Epoch 26/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 0.9743 - accuracy: 0.6238 - val_loss: 0.8841 - val_accuracy: 0.6204\n",
      "Epoch 27/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 0.9300 - accuracy: 0.6413 - val_loss: 0.9208 - val_accuracy: 0.6352\n",
      "Epoch 28/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 0.8994 - accuracy: 0.6579 - val_loss: 1.0826 - val_accuracy: 0.5870\n",
      "Epoch 29/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 0.8352 - accuracy: 0.6651 - val_loss: 1.5430 - val_accuracy: 0.5185\n",
      "Epoch 30/100\n",
      "158/158 [==============================] - 5s 31ms/step - loss: 0.8702 - accuracy: 0.6659 - val_loss: 1.2901 - val_accuracy: 0.5778\n",
      "Epoch 31/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 0.8212 - accuracy: 0.6944 - val_loss: 1.2616 - val_accuracy: 0.5352\n",
      "Epoch 32/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 0.8373 - accuracy: 0.6897 - val_loss: 1.0378 - val_accuracy: 0.5889\n",
      "Epoch 33/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 0.7631 - accuracy: 0.6984 - val_loss: 1.0979 - val_accuracy: 0.5556\n",
      "Epoch 34/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 0.7226 - accuracy: 0.7254 - val_loss: 1.1150 - val_accuracy: 0.6000\n",
      "Epoch 35/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 0.6851 - accuracy: 0.7214 - val_loss: 1.1696 - val_accuracy: 0.5833\n",
      "Epoch 36/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 0.7303 - accuracy: 0.7079 - val_loss: 1.1733 - val_accuracy: 0.5944\n",
      "Epoch 37/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 0.7367 - accuracy: 0.7373 - val_loss: 1.1781 - val_accuracy: 0.6333\n",
      "Epoch 38/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 0.6952 - accuracy: 0.7444 - val_loss: 1.1786 - val_accuracy: 0.5907\n",
      "Epoch 39/100\n",
      "158/158 [==============================] - 5s 31ms/step - loss: 0.7120 - accuracy: 0.7278 - val_loss: 0.8094 - val_accuracy: 0.7074\n",
      "Epoch 40/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 0.7072 - accuracy: 0.7278 - val_loss: 0.8401 - val_accuracy: 0.7037\n",
      "Epoch 41/100\n",
      "158/158 [==============================] - 5s 31ms/step - loss: 0.5920 - accuracy: 0.7817 - val_loss: 0.8982 - val_accuracy: 0.6722\n",
      "Epoch 42/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 0.6046 - accuracy: 0.7603 - val_loss: 0.7121 - val_accuracy: 0.7389\n",
      "Epoch 43/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 0.5539 - accuracy: 0.7913 - val_loss: 1.7278 - val_accuracy: 0.5444\n",
      "Epoch 44/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 0.5683 - accuracy: 0.7825 - val_loss: 1.2351 - val_accuracy: 0.6278\n",
      "Epoch 45/100\n",
      "158/158 [==============================] - 4s 28ms/step - loss: 0.6862 - accuracy: 0.7413 - val_loss: 0.9739 - val_accuracy: 0.6148\n",
      "Epoch 46/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 0.5878 - accuracy: 0.7865 - val_loss: 0.9285 - val_accuracy: 0.6537\n",
      "Epoch 47/100\n",
      "158/158 [==============================] - 5s 31ms/step - loss: 0.5653 - accuracy: 0.7913 - val_loss: 0.5587 - val_accuracy: 0.7833\n",
      "Epoch 48/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 0.5524 - accuracy: 0.7921 - val_loss: 1.3321 - val_accuracy: 0.5667\n",
      "Epoch 49/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 0.5541 - accuracy: 0.7929 - val_loss: 0.7403 - val_accuracy: 0.7037\n",
      "Epoch 50/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 0.5143 - accuracy: 0.7984 - val_loss: 0.9070 - val_accuracy: 0.7000\n",
      "Epoch 51/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 0.4827 - accuracy: 0.8246 - val_loss: 0.8351 - val_accuracy: 0.6926\n",
      "Epoch 52/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 0.4597 - accuracy: 0.8405 - val_loss: 0.6961 - val_accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 0.4868 - accuracy: 0.8294 - val_loss: 0.9252 - val_accuracy: 0.6704\n",
      "Epoch 54/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 0.4622 - accuracy: 0.8286 - val_loss: 0.6435 - val_accuracy: 0.7389\n",
      "Epoch 55/100\n",
      "158/158 [==============================] - 5s 31ms/step - loss: 0.5349 - accuracy: 0.8024 - val_loss: 0.8601 - val_accuracy: 0.6852\n",
      "Epoch 56/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 0.5100 - accuracy: 0.8143 - val_loss: 0.7546 - val_accuracy: 0.7241\n",
      "Epoch 57/100\n",
      "158/158 [==============================] - 5s 32ms/step - loss: 0.5453 - accuracy: 0.8079 - val_loss: 0.5642 - val_accuracy: 0.8111\n",
      "Epoch 58/100\n",
      "158/158 [==============================] - 5s 32ms/step - loss: 0.4177 - accuracy: 0.8579 - val_loss: 1.0697 - val_accuracy: 0.6963\n",
      "Epoch 59/100\n",
      "158/158 [==============================] - 5s 31ms/step - loss: 0.5227 - accuracy: 0.8079 - val_loss: 0.5645 - val_accuracy: 0.7833\n",
      "Epoch 60/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 0.3903 - accuracy: 0.8619 - val_loss: 0.6623 - val_accuracy: 0.7444\n",
      "Epoch 61/100\n",
      "158/158 [==============================] - 5s 29ms/step - loss: 0.4300 - accuracy: 0.8429 - val_loss: 0.8028 - val_accuracy: 0.7481\n",
      "Epoch 62/100\n",
      "158/158 [==============================] - 5s 30ms/step - loss: 0.3936 - accuracy: 0.8579 - val_loss: 0.8852 - val_accuracy: 0.6796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e14e89aef0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=8, callbacks=[tb_callback, my_callback, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " conv1d_28_input (InputLayer)   [(None, 100, 126)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)             (None, 100, 64)      56512       ['conv1d_28_input[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 100, 64)     256         ['conv1d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 100, 64)      0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)             (None, 100, 64)      12352       ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 100, 64)     256         ['conv1d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 100, 64)      0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)             (None, 100, 64)      12352       ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 100, 64)     256         ['conv1d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)             (None, 100, 64)      4160        ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 100, 64)      0           ['batch_normalization_28[0][0]', \n",
      "                                                                  'conv1d_31[0][0]']              \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 100, 64)      0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 100, 64)      12352       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 100, 64)     256         ['conv1d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 100, 64)      0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)             (None, 100, 64)      12352       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 100, 64)     256         ['conv1d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)             (None, 100, 64)      4160        ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 100, 64)      0           ['batch_normalization_30[0][0]', \n",
      "                                                                  'conv1d_34[0][0]']              \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 100, 64)      0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 50, 64)      0           ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)             (None, 25, 128)      24704       ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 25, 128)     512         ['conv1d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 25, 128)      0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)             (None, 25, 128)      49280       ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 25, 128)     512         ['conv1d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)             (None, 25, 128)      8320        ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 25, 128)      0           ['batch_normalization_32[0][0]', \n",
      "                                                                  'conv1d_37[0][0]']              \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 25, 128)      0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)             (None, 25, 128)      49280       ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 25, 128)     512         ['conv1d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 25, 128)      0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)             (None, 25, 128)      49280       ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 25, 128)     512         ['conv1d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)             (None, 25, 128)      16512       ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 25, 128)      0           ['batch_normalization_34[0][0]', \n",
      "                                                                  'conv1d_40[0][0]']              \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 25, 128)      0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 12, 128)     0           ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 6, 256)       98560       ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 6, 256)      1024        ['conv1d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 6, 256)       0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)             (None, 6, 256)       196864      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 6, 256)      1024        ['conv1d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)             (None, 6, 256)       33024       ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 6, 256)       0           ['batch_normalization_36[0][0]', \n",
      "                                                                  'conv1d_43[0][0]']              \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 6, 256)       0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)             (None, 6, 256)       196864      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 6, 256)      1024        ['conv1d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 6, 256)       0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)             (None, 6, 256)       196864      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 6, 256)      1024        ['conv1d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)             (None, 6, 256)       65792       ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 6, 256)       0           ['batch_normalization_38[0][0]', \n",
      "                                                                  'conv1d_46[0][0]']              \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 6, 256)       0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 3, 256)      0           ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)             (None, 2, 512)       393728      ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 2, 512)      2048        ['conv1d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 2, 512)       0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_48 (Conv1D)             (None, 2, 512)       786944      ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 2, 512)      2048        ['conv1d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_49 (Conv1D)             (None, 2, 512)       131584      ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 2, 512)       0           ['batch_normalization_40[0][0]', \n",
      "                                                                  'conv1d_49[0][0]']              \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 2, 512)       0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_50 (Conv1D)             (None, 2, 512)       786944      ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 2, 512)      2048        ['conv1d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 2, 512)       0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_51 (Conv1D)             (None, 2, 512)       786944      ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 2, 512)      2048        ['conv1d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_52 (Conv1D)             (None, 2, 512)       262656      ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 2, 512)       0           ['batch_normalization_42[0][0]', \n",
      "                                                                  'conv1d_52[0][0]']              \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 2, 512)       0           ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 512)         0           ['activation_41[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          131328      ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 256)         1024        ['dense[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 9)            2313        ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,398,665\n",
      "Trainable params: 4,390,345\n",
      "Non-trainable params: 8,320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ResNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('ResNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 9ms/step\n",
      "Train Accuracy :-> \n",
      "91.19047619047619\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_train)\n",
    "ytrue = np.argmax(y_train, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "print(\"Train Accuracy :-> \")\n",
    "print(accuracy_score(ytrue, yhat)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 21ms/step\n",
      "Test Accuracy :-> \n",
      "78.33333333333333\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "print(\"Test Accuracy :-> \")\n",
    "print(accuracy_score(ytrue, yhat)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
