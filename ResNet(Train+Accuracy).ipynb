{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Add, MaxPooling1D, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('dataset')\n",
    "actions = np.array(['zero', 'one', 'two','three', 'four', 'five', 'six', 'seven', 'eight', 'nine'])\n",
    "sequence_length = 100\n",
    "num_features = 126\n",
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "\n",
    "for action in actions:\n",
    "    action_path = os.path.join(DATA_PATH, action)\n",
    "    for sequence in np.array(os.listdir(action_path)).astype(int):\n",
    "        frame_paths = [\n",
    "            os.path.join(action_path, str(sequence), \"{}.npy\".format(frame_num))\n",
    "            for frame_num in range(sequence_length)\n",
    "        ]\n",
    "        window = [np.load(frame_path) for frame_path in frame_paths]\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('ResNet_Logs')\n",
    "callback = TensorBoard(log_dir=log_dir)\n",
    "ACCURACY_THRESHOLD = 0.95\n",
    "\n",
    "class MyCallback(tf.keras.callbacks.Callback): \n",
    "    def __init__(self, monitor_metric='accuracy'):\n",
    "        super(MyCallback, self).__init__()\n",
    "        self.monitor_metric = monitor_metric\n",
    "        self.threshold = ACCURACY_THRESHOLD\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        current_metric_value = logs.get(self.monitor_metric)\n",
    "        if current_metric_value is not None and current_metric_value > self.threshold:\n",
    "            print(f\"\\nReached {self.threshold * 100:.2f}% {self.monitor_metric}, stopping training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "my_callback = MyCallback(monitor_metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    shortcut = x\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    shortcut = Conv1D(filters, 1, strides=stride, padding='same')(shortcut)\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=7, padding='same', input_shape=(sequence_length, num_features)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "input_tensor = model.output\n",
    "\n",
    "x = residual_block(input_tensor, filters=64)\n",
    "x = residual_block(x, filters=64)\n",
    "x = MaxPooling1D(2)(x)\n",
    "\n",
    "x = residual_block(x, filters=128, stride=2)\n",
    "x = residual_block(x, filters=128)\n",
    "x = MaxPooling1D(2)(x)\n",
    "\n",
    "x = residual_block(x, filters=256, stride=2)\n",
    "x = residual_block(x, filters=256)\n",
    "x = MaxPooling1D(2)(x)\n",
    "\n",
    "x = residual_block(x, filters=512, stride=2)\n",
    "x = residual_block(x, filters=512)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "output_tensor = Dense(actions.shape[0], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=model.input, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  6/175 [>.............................] - ETA: 4s - loss: 3.4909 - accuracy: 0.0208     WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0223s vs `on_train_batch_end` time: 0.1680s). Check your callbacks.\n",
      "175/175 [==============================] - 16s 28ms/step - loss: 2.6354 - accuracy: 0.1314 - val_loss: 2.4366 - val_accuracy: 0.0983\n",
      "Epoch 2/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 2.3432 - accuracy: 0.1571 - val_loss: 2.2781 - val_accuracy: 0.2017\n",
      "Epoch 3/100\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 2.1547 - accuracy: 0.2321 - val_loss: 2.2380 - val_accuracy: 0.2533\n",
      "Epoch 4/100\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 2.0397 - accuracy: 0.2579 - val_loss: 1.9167 - val_accuracy: 0.3117\n",
      "Epoch 5/100\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 1.9273 - accuracy: 0.3007 - val_loss: 2.0393 - val_accuracy: 0.2650\n",
      "Epoch 6/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 1.7732 - accuracy: 0.3193 - val_loss: 2.4690 - val_accuracy: 0.2650\n",
      "Epoch 7/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 1.6932 - accuracy: 0.3814 - val_loss: 1.5003 - val_accuracy: 0.4150\n",
      "Epoch 8/100\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 1.5806 - accuracy: 0.4143 - val_loss: 2.2659 - val_accuracy: 0.2783\n",
      "Epoch 9/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 1.5768 - accuracy: 0.4043 - val_loss: 1.5695 - val_accuracy: 0.3917\n",
      "Epoch 10/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 1.4069 - accuracy: 0.4671 - val_loss: 1.6888 - val_accuracy: 0.4017\n",
      "Epoch 11/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 1.4436 - accuracy: 0.4407 - val_loss: 1.4399 - val_accuracy: 0.4167\n",
      "Epoch 12/100\n",
      "175/175 [==============================] - 4s 25ms/step - loss: 1.3548 - accuracy: 0.4579 - val_loss: 1.3578 - val_accuracy: 0.4883\n",
      "Epoch 13/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 1.2706 - accuracy: 0.5193 - val_loss: 1.2005 - val_accuracy: 0.5383\n",
      "Epoch 14/100\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 1.2165 - accuracy: 0.5286 - val_loss: 1.0624 - val_accuracy: 0.5550\n",
      "Epoch 15/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 1.1139 - accuracy: 0.5614 - val_loss: 1.4345 - val_accuracy: 0.4850\n",
      "Epoch 16/100\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 1.1163 - accuracy: 0.5500 - val_loss: 1.5076 - val_accuracy: 0.4600\n",
      "Epoch 17/100\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 1.0612 - accuracy: 0.6079 - val_loss: 1.1653 - val_accuracy: 0.5800\n",
      "Epoch 18/100\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 1.0178 - accuracy: 0.6021 - val_loss: 1.0496 - val_accuracy: 0.5650\n",
      "Epoch 19/100\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.9939 - accuracy: 0.6107 - val_loss: 1.1869 - val_accuracy: 0.5217\n",
      "Epoch 20/100\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 1.0237 - accuracy: 0.6207 - val_loss: 1.1749 - val_accuracy: 0.5933\n",
      "Epoch 21/100\n",
      "175/175 [==============================] - 4s 25ms/step - loss: 0.9468 - accuracy: 0.6371 - val_loss: 1.0817 - val_accuracy: 0.5683\n",
      "Epoch 22/100\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.8825 - accuracy: 0.6600 - val_loss: 1.0432 - val_accuracy: 0.5850\n",
      "Epoch 23/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.9176 - accuracy: 0.6621 - val_loss: 0.8641 - val_accuracy: 0.6550\n",
      "Epoch 24/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.8318 - accuracy: 0.6907 - val_loss: 0.8119 - val_accuracy: 0.6900\n",
      "Epoch 25/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.8307 - accuracy: 0.6907 - val_loss: 1.2884 - val_accuracy: 0.5617\n",
      "Epoch 26/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.8230 - accuracy: 0.6929 - val_loss: 1.3380 - val_accuracy: 0.5383\n",
      "Epoch 27/100\n",
      "175/175 [==============================] - 4s 25ms/step - loss: 0.7687 - accuracy: 0.7021 - val_loss: 1.2841 - val_accuracy: 0.5333\n",
      "Epoch 28/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.7554 - accuracy: 0.7214 - val_loss: 0.7795 - val_accuracy: 0.7067\n",
      "Epoch 29/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.7425 - accuracy: 0.7336 - val_loss: 1.3423 - val_accuracy: 0.5717\n",
      "Epoch 30/100\n",
      "175/175 [==============================] - 4s 26ms/step - loss: 0.7042 - accuracy: 0.7321 - val_loss: 1.0955 - val_accuracy: 0.6400\n",
      "Epoch 31/100\n",
      "175/175 [==============================] - 4s 25ms/step - loss: 0.7102 - accuracy: 0.7457 - val_loss: 0.9664 - val_accuracy: 0.6400\n",
      "Epoch 32/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.7064 - accuracy: 0.7307 - val_loss: 1.6196 - val_accuracy: 0.5700\n",
      "Epoch 33/100\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.6851 - accuracy: 0.7429 - val_loss: 0.6872 - val_accuracy: 0.7117\n",
      "Epoch 34/100\n",
      "175/175 [==============================] - 4s 25ms/step - loss: 0.6656 - accuracy: 0.7600 - val_loss: 0.8134 - val_accuracy: 0.7133\n",
      "Epoch 35/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.7126 - accuracy: 0.7357 - val_loss: 0.8193 - val_accuracy: 0.7017\n",
      "Epoch 36/100\n",
      "175/175 [==============================] - 4s 25ms/step - loss: 0.5885 - accuracy: 0.7986 - val_loss: 1.3950 - val_accuracy: 0.5150\n",
      "Epoch 37/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.5959 - accuracy: 0.7857 - val_loss: 0.8308 - val_accuracy: 0.7100\n",
      "Epoch 38/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.5701 - accuracy: 0.8093 - val_loss: 1.2255 - val_accuracy: 0.6133\n",
      "Epoch 39/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.5232 - accuracy: 0.8193 - val_loss: 0.5990 - val_accuracy: 0.7750\n",
      "Epoch 40/100\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.5242 - accuracy: 0.8064 - val_loss: 0.6590 - val_accuracy: 0.7683\n",
      "Epoch 41/100\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.5052 - accuracy: 0.8300 - val_loss: 1.6420 - val_accuracy: 0.5783\n",
      "Epoch 42/100\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.5075 - accuracy: 0.8150 - val_loss: 1.6673 - val_accuracy: 0.5300\n",
      "Epoch 43/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.5065 - accuracy: 0.8250 - val_loss: 1.3231 - val_accuracy: 0.6633\n",
      "Epoch 44/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.5154 - accuracy: 0.8150 - val_loss: 1.2635 - val_accuracy: 0.6233\n",
      "Epoch 45/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.4638 - accuracy: 0.8350 - val_loss: 0.8082 - val_accuracy: 0.7067\n",
      "Epoch 46/100\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.4456 - accuracy: 0.8471 - val_loss: 0.9207 - val_accuracy: 0.6883\n",
      "Epoch 47/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.4631 - accuracy: 0.8300 - val_loss: 0.6742 - val_accuracy: 0.7800\n",
      "Epoch 48/100\n",
      "175/175 [==============================] - 4s 26ms/step - loss: 0.4578 - accuracy: 0.8314 - val_loss: 1.2758 - val_accuracy: 0.6083\n",
      "Epoch 49/100\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.4118 - accuracy: 0.8471 - val_loss: 0.7442 - val_accuracy: 0.7400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6b3cf5b70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=8, callbacks=[tb_callback, my_callback, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " conv1d_input (InputLayer)      [(None, 100, 126)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 100, 64)      56512       ['conv1d_input[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 100, 64)     256         ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 100, 64)      0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 100, 64)      12352       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 100, 64)     256         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 100, 64)      0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 100, 64)      12352       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 100, 64)     256         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 100, 64)      4160        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 100, 64)      0           ['batch_normalization_2[0][0]',  \n",
      "                                                                  'conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 100, 64)      0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 100, 64)      12352       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 100, 64)     256         ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 100, 64)      0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 100, 64)      12352       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 100, 64)     256         ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 100, 64)      4160        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 100, 64)      0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 100, 64)      0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 50, 64)       0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 25, 128)      24704       ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 25, 128)     512         ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 25, 128)      0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 25, 128)      49280       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 25, 128)     512         ['conv1d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 25, 128)      8320        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 25, 128)      0           ['batch_normalization_6[0][0]',  \n",
      "                                                                  'conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 25, 128)      0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 25, 128)      49280       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 25, 128)     512         ['conv1d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 25, 128)      0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 25, 128)      49280       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 25, 128)     512         ['conv1d_11[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 25, 128)      16512       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 25, 128)      0           ['batch_normalization_8[0][0]',  \n",
      "                                                                  'conv1d_12[0][0]']              \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 25, 128)      0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 12, 128)     0           ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 6, 256)       98560       ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 6, 256)      1024        ['conv1d_13[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 6, 256)       0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 6, 256)       196864      ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 6, 256)      1024        ['conv1d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 6, 256)       33024       ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 6, 256)       0           ['batch_normalization_10[0][0]', \n",
      "                                                                  'conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 6, 256)       0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 6, 256)       196864      ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 6, 256)      1024        ['conv1d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 6, 256)       0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 6, 256)       196864      ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 6, 256)      1024        ['conv1d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 6, 256)       65792       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 6, 256)       0           ['batch_normalization_12[0][0]', \n",
      "                                                                  'conv1d_18[0][0]']              \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 6, 256)       0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 3, 256)      0           ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 2, 512)       393728      ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 2, 512)      2048        ['conv1d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 2, 512)       0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 2, 512)       786944      ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 2, 512)      2048        ['conv1d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 2, 512)       131584      ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 2, 512)       0           ['batch_normalization_14[0][0]', \n",
      "                                                                  'conv1d_21[0][0]']              \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 2, 512)       0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 2, 512)       786944      ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 2, 512)      2048        ['conv1d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 2, 512)       0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 2, 512)       786944      ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 2, 512)      2048        ['conv1d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 2, 512)       262656      ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 2, 512)       0           ['batch_normalization_16[0][0]', \n",
      "                                                                  'conv1d_24[0][0]']              \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 2, 512)       0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 512)         0           ['activation_16[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          131328      ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 256)         1024        ['dense[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           2570        ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,398,922\n",
      "Trainable params: 4,390,602\n",
      "Non-trainable params: 8,320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ResNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('ResNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 8ms/step\n",
      "Train Accuracy :-> \n",
      "87.42857142857143\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_train)\n",
    "ytrue = np.argmax(y_train, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "print(\"Train Accuracy :-> \")\n",
    "print(accuracy_score(ytrue, yhat)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 18ms/step\n",
      "Test Accuracy :-> \n",
      "77.5\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "print(\"Test Accuracy :-> \")\n",
    "print(accuracy_score(ytrue, yhat)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
